{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "logo-top",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo_bic.png\" width=\"20%\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "title-top",
   "metadata": {},
   "source": [
    "# Python for Algorithmic Trading\n",
    "## Vectorized Lagged-Returns OLS Strategy on a Single Asset\n",
    "\n",
    "&copy; Dr. Yves J. Hilpisch<br>\n",
    "AI-Powered by GPT 5.1<br>\n",
    "The Python Quants GmbH | https://tpq.io<br>\n",
    "https://hilpisch.com | https://linktr.ee/dyjh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goals",
   "metadata": {},
   "source": [
    "## Notebook Goals\n",
    "\n",
    "This notebook walks through the lagged-returns OLS strategy from Sections 5 and 6 in a fully vectorized form. You will\n",
    "\n",
    "- load daily prices prices from `data/epat_eod.csv`,\n",
    "- construct lagged log-return features,\n",
    "- fit an OLS model to predict tomorrow's return from past returns,\n",
    "- translate predictions into positions and equity curves, and\n",
    "- compare the strategy against buy-and-hold and a coin-flip benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized lagged-returns OLS backtest in notebook form.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")  #  consistent look\n",
    "plt.rcParams.update({\"figure.dpi\": 250})\n",
    "\n",
    "DATA_PATH = Path(\"../data/epat_eod.csv\")\n",
    "DATA_URL = (\n",
    "    \"https://raw.githubusercontent.com/yhilpisch/epatcode/\"\n",
    "    \"refs/heads/main/data/epat_eod.csv\"\n",
    ")\n",
    "DATA_SRC = DATA_PATH if DATA_PATH.is_file() else DATA_URL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect Time Series Data\n",
    "\n",
    "We start by loading the end-of-day dataset and extracting the symbol column as a clean price series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"EURUSD\"\n",
    "end = '2025-12-31'\n",
    "raw = pd.read_csv(DATA_SRC, parse_dates=[\"Date\"]).set_index(\"Date\").sort_index().loc[:end]\n",
    "data = raw[symbol].astype(float).dropna()\n",
    "display(data.to_frame(symbol).tail())\n",
    "print(f\"Date range: {data.index.min().date()} â†’ {data.index.max().date()} ({len(data):,} obs)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4c8a6-9e69-4a33-9a79-9891c892177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lags",
   "metadata": {},
   "source": [
    "## 2. Construct Lagged-Returns Features\n",
    "\n",
    "We follow the article and use a fixed number of lags (for example, seven) of daily log-returns as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lags-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lagged_returns(prices: pd.Series,\n",
    "                        lags: int = 5) -> tuple[np.ndarray, np.ndarray, pd.DatetimeIndex]:\n",
    "    \"\"\"Compute log-returns and assemble a lagged design matrix.\"\"\"\n",
    "\n",
    "    log_prices = np.log(prices.to_numpy())\n",
    "    rets = np.diff(log_prices)  #  r_t = log S_t - log S_{t-1}\n",
    "    dates = prices.index[1:]\n",
    "\n",
    "    n = rets.shape[0]\n",
    "    if n <= lags:\n",
    "        raise ValueError(\"Not enough observations for the chosen number of lags.\")\n",
    "\n",
    "    X = np.column_stack(\n",
    "        [rets[(lags - k):(n - k)] for k in range(1, lags + 1)]\n",
    "    )  #  columns r_{t-1},...,r_{t-lags}\n",
    "    y = rets[lags:]  #  target r_t\n",
    "    dates_eff = dates[lags:]\n",
    "    return X, y, dates_eff\n",
    "\n",
    "lags = 7\n",
    "X, y, dates = make_lagged_returns(data, lags=lags)\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diag-lags",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: inspect first rows of target and lagged returns.\n",
    "rows = min(5, y.shape[0])\n",
    "cols = min(X.shape[1], 7)\n",
    "diag_cols = [y[:rows]] + [X[:rows, k] for k in range(cols)]\n",
    "diag_labels = [\"y_t\"] + [f\"r_t_minus_{k + 1}\" for k in range(cols)]\n",
    "diag_df = pd.DataFrame(\n",
    "    np.column_stack(diag_cols),\n",
    "    columns=diag_labels,\n",
    "    index=dates[:rows],\n",
    ")\n",
    "diag_df.round(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ols",
   "metadata": {},
   "source": [
    "## 3. Fit the OLS Model\n",
    "\n",
    "Next we fit the linear model\n",
    "$$r_t = \\alpha + \\beta^\\top x_t + \\varepsilon_t$$\n",
    "where the components of $x_t$ are lagged returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ols-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ols(X: np.ndarray, y: np.ndarray, normalize: bool = False) -> np.ndarray:\n",
    "    \"\"\"Estimate y = beta_0 + X beta via OLS and return coefficients.\n",
    "\n",
    "    If ``normalize`` is True, each feature column is standardized to\n",
    "    zero mean and unit variance before fitting. This can improve\n",
    "    numerical conditioning when features have different scales,\n",
    "    but the trading logic based on the sign of predictions remains\n",
    "    unchanged.\n",
    "    \"\"\"\n",
    "\n",
    "    if normalize:\n",
    "        mean = X.mean(axis=0)\n",
    "        std = X.std(axis=0, ddof=1)\n",
    "        std[std == 0.0] = 1.0  #  avoid division by zero for constant cols\n",
    "        X_use = (X - mean) / std\n",
    "    else:\n",
    "        X_use = X\n",
    "\n",
    "    X_design = np.column_stack([np.ones(X_use.shape[0]), X_use])  #  add intercept\n",
    "    beta = np.linalg.lstsq(X_design, np.sign(y), rcond=None)[0]\n",
    "    return beta\n",
    "\n",
    "\n",
    "beta = fit_ols(X, y, normalize=False)\n",
    "beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strategy",
   "metadata": {},
   "source": [
    "## 4. From Predictions to Positions\n",
    "\n",
    "We convert one-step-ahead predictions into long/short positions, lagging the signals by one day to avoid look-ahead bias. Transaction costs are modelled as a simple proportional charge on changes in position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategy-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lag_strategy(X: np.ndarray,\n",
    "                     y: np.ndarray,\n",
    "                     beta: np.ndarray,\n",
    "                     cost: float = 0.0001) -> np.ndarray:\n",
    "    \"\"\"Compute strategy returns from lagged OLS predictions.\"\"\"\n",
    "\n",
    "    X_design = np.column_stack([np.ones(X.shape[0]), X])\n",
    "    y_pred = X_design @ beta  #  forecasts of r_t\n",
    "\n",
    "    pos = np.sign(y_pred)  #  raw positions -1, 0, +1\n",
    "    strat_rets = pos * y  #  gross strategy returns\n",
    "\n",
    "    turnover = np.abs(pos[1:] - pos[:-1])  #  trades per step\n",
    "    strat_rets[1:] = strat_rets[1:] - cost * turnover\n",
    "    return strat_rets\n",
    "\n",
    "\n",
    "strat_rets = run_lag_strategy(X, y, beta)\n",
    "strat_rets[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perf",
   "metadata": {},
   "source": [
    "## 5. Performance Metrics: Buy & Hold vs Strategy\n",
    "\n",
    "Before looking at equity curves, it is useful to compare basic performance metrics for buy-and-hold and the lagged-returns strategy on the same return window. We use the aligned log-return vectors `y` (for the symbol) and `strat_rets` (for the strategy) to compute annualized return, volatility, and Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perf-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = 252  #  rough number of trading days per year\n",
    "\n",
    "def max_drawdown_and_duration(equity: np.ndarray) -> tuple[float, int]:\n",
    "    \"\"\"Compute maximum drawdown and its duration (in periods).\"\"\"\n",
    "\n",
    "    peak = np.maximum.accumulate(equity)\n",
    "    dd = equity / peak - 1.0  #  drawdown series (<= 0)\n",
    "    underwater = dd < 0.0\n",
    "    max_dur = 0\n",
    "    cur = 0\n",
    "    for flag in underwater:\n",
    "        if flag:\n",
    "            cur += 1\n",
    "            if cur > max_dur:\n",
    "                max_dur = cur\n",
    "        else:\n",
    "            cur = 0\n",
    "    return float(dd.min()), int(max_dur)\n",
    "\n",
    "\n",
    "# equity curves on the effective window shared by y and strat_rets\n",
    "eq_bh = np.cumprod(1.0 + y)\n",
    "eq_strat = np.cumprod(1.0 + strat_rets)\n",
    "\n",
    "# buy-and-hold metrics\n",
    "ann_ret_bh = y.mean() * trading_days\n",
    "ann_vol_bh = y.std(ddof=1) * np.sqrt(trading_days)\n",
    "sharpe_bh = ann_ret_bh / ann_vol_bh if ann_vol_bh > 0.0 else np.nan\n",
    "total_ret_bh = eq_bh[-1] - 1.0\n",
    "max_dd_bh, dur_bh = max_drawdown_and_duration(eq_bh)\n",
    "\n",
    "# strategy metrics\n",
    "ann_ret_strat = strat_rets.mean() * trading_days\n",
    "ann_vol_strat = strat_rets.std(ddof=1) * np.sqrt(trading_days)\n",
    "sharpe_strat = (ann_ret_strat / ann_vol_strat\n",
    "                if ann_vol_strat > 0.0 else np.nan)\n",
    "total_ret_strat = eq_strat[-1] - 1.0\n",
    "max_dd_strat, dur_strat = max_drawdown_and_duration(eq_strat)\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"ann_return\": [ann_ret_bh, ann_ret_strat],\n",
    "        \"ann_vol\": [ann_vol_bh, ann_vol_strat],\n",
    "        \"sharpe\": [sharpe_bh, sharpe_strat],\n",
    "        \"total_return\": [total_ret_bh, total_ret_strat],\n",
    "        \"max_drawdown\": [max_dd_bh, max_dd_strat],\n",
    "        \"dd_duration\": [dur_bh, dur_strat],\n",
    "    },\n",
    "    index=[\"buy_and_hold\", \"lag_ols_strategy\"],\n",
    ")\n",
    "summary.round(3).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equity",
   "metadata": {},
   "source": [
    "## 6. Equity Curves and Benchmarks\n",
    "\n",
    "Finally we compare the lagged-returns strategy against buy-and-hold and a coin-flip long/short benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equity-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_bh = np.cumprod(1.0 + y)  #  buy-and-hold equity\n",
    "eq_strat = np.cumprod(1.0 + strat_rets)  #  strategy equity\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "coin_pos = rng.choice([-1.0, 1.0], size=y.shape[0])  #  random long/short\n",
    "coin_rets = coin_pos * y\n",
    "eq_coin = np.cumprod(1.0 + coin_rets)  #  coin-flip equity\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 4))\n",
    "ax.plot(dates, eq_strat, label=\"Lag-OLS strategy\")\n",
    "ax.plot(dates, eq_bh, label=f\"Buy & hold ({symbol})\", ls='--', lw=1)\n",
    "ax.plot(dates, eq_coin, label=\"Coin-flip long/short\", ls='-.', lw=1)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"normalized equity\")\n",
    "ax.set_title(f\"Vectorized lagged-returns strategy on {symbol}\")\n",
    "ax.legend(loc=\"best\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrap-up",
   "metadata": {},
   "source": [
    "## 7. Extensions\n",
    "\n",
    "The vectorized pattern in this notebook extends easily:\n",
    "\n",
    "- change the number of lags or add further features (for example, moving-average signals),\n",
    "- adjust the mapping from predictions to positions (thresholds, scaling, volatility targeting), and\n",
    "- move from a single time series column to a multi-asset matrix for cross-sectional strategies.\n",
    "\n",
    "The OOP backtest in the article wraps these steps into a reusable class; you can think of this notebook as the functional prototype that the class encapsulates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "footer-logo",
   "metadata": {},
   "source": [
    "<img src=\"https://hilpisch.com/tpq_logo_bic.png\" width=\"20%\" align=\"right\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
